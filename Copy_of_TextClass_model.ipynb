{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TextClass_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nimesh-Patel/Agent-Based-Modeling/blob/master/Copy_of_TextClass_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WNkH8KXPXnd",
        "colab_type": "text"
      },
      "source": [
        "# **Classifier for NIOSH competition**\n",
        "\n",
        "**Nim Pat**\n",
        "\n",
        "**11.21.2019**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roro_pt5Zj2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbPvBIIx2lQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###  FIRST PART, Run this First and Upload Files \n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n51OmvJT26QW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Run Model\n",
        "\n",
        "# import libraries\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "\n",
        "## import files\n",
        "import io\n",
        "df_train = pd.read_csv(io.BytesIO(uploaded['Train_Clean.csv']), encoding='iso-8859-1')\n",
        "df_val = pd.read_csv(io.BytesIO(uploaded['Train_Clean.csv']), encoding='iso-8859-1')\n",
        "df_test = pd.read_csv(io.BytesIO(uploaded['test_Clean.csv']), encoding='iso-8859-1')\n",
        "\n",
        "## language model\n",
        "\n",
        "# data for language model\n",
        "data_lm = TextLMDataBunch.from_df(train_df = df_train, valid_df = df_val, path=\"\")\n",
        "\n",
        "# train language model\n",
        "learn_lm = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.7)\n",
        "learn_lm.lr_find(start_lr = slice(10e-7, 10e-5), end_lr=slice(0.1, 10))\n",
        "learn_lm.recorder.plot(suggestion=True)\n",
        "best_lm_lr = learn_lm.recorder.min_grad_lr\n",
        "learn_lm.fit_one_cycle(10, best_lm_lr)\n",
        "learn_lm.unfreeze()\n",
        "learn_lm.fit_one_cycle(10, best_lm_lr)\n",
        "print(\"Finish Train Lang model\")\n",
        "# save encoder\n",
        "learn_lm.save_encoder('ft_enc')\n",
        "\n",
        "## classifier\n",
        "print(\"Starting classifer data import\")\n",
        "# data for classifier\n",
        "data_clas = TextClasDataBunch.from_df(path=\"\", train_df = df_train, valid_df = df_val, test_df=df_test, vocab=data_lm.train_ds.vocab, bs=32)\n",
        "print(\"Starting Train classifer\")\n",
        "# train classifier\n",
        "learn_clas = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.7)\n",
        "learn_clas.load_encoder('ft_enc')\n",
        "learn_clas.lr_find(start_lr=slice(10e-7, 10e-5), end_lr=slice(0.1, 10))\n",
        "learn_clas.recorder.plot(skip_end=1, suggestion=True)\n",
        "best_clf_lr = learn_clas.recorder.min_grad_lr\n",
        "learn_clas.fit_one_cycle(10, best_clf_lr)\n",
        "learn_clas.freeze_to(-2)\n",
        "learn_clas.fit_one_cycle(10, slice(best_clf_lr/2., best_clf_lr))\n",
        "learn_clas.unfreeze()\n",
        "learn_clas.fit_one_cycle(10, slice(best_clf_lr/100, best_clf_lr))\n",
        "\n",
        "## predictions\n",
        "\n",
        "# generate predictions\n",
        "preds, targets = learn_clas.get_preds(DatasetType.Test, ordered=True)\n",
        "predictions = np.argmax(preds, axis = 1)\n",
        "test_preds=predictions.tolist()\n",
        "preds_df=pd.DataFrame(test_preds)\n",
        "\n",
        "# re-label\n",
        "outcomes=list(set(df_train['label']))\n",
        "di={}\n",
        "i=0\n",
        "for o in outcomes:\n",
        "  di[i]=o\n",
        "  i=i+1\n",
        "  \n",
        "new_preds=preds_df.replace(di) \n",
        "\n",
        "\n",
        "# export predictions\n",
        "new_preds.to_csv('preds.csv', index=False, header=False)\n",
        "files.download('preds.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}